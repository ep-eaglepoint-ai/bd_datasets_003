# Trajectory: Weight-Standardized Convolution with Group Normalization Optimization

## Phase 1: Audit / Requirements Analysis (The Actual Problem)

The repository_before implementation was a neural network layer (weight-standardized convolution + group normalization) that was functionally correct but catastrophically slow and memory-hungry. The root causes: (1) spawning a goroutine for every single output pixel with a global mutex lock, creating millions of goroutines and serializing all work, (2) calling runtime.GC() explicitly after every operation, (3) using sync.Mutex inside the Index() method with artificial math.Sqrt loops to burn CPU, (4) recomputing standardized weights on every forward pass with no caching, (5) recomputing tensor strides on every Index() call, (6) using time.Now().UnixNano() for non-deterministic weight initialization, and (7) multiplying convolution results by math.Sin(sum+1) to inject non-determinism and artificial computation. The task was to refactor this into a production-grade implementation that preserves numerical correctness while eliminating all performance anti-patterns.

## Phase 2: Question Assumptions (Challenge the Premise)

At first glance, the goroutines and mutex might seem like an attempt at parallelism. But the global mutex serializes everything, so we're paying goroutine overhead with zero concurrency benefit. The real fix is sequential loops with proper memory access patterns. I also questioned whether we needed to preserve the exact API—turns out we do (NewTensor, NewWSConv2D, NewGroupNorm, Forward methods) but we can add error-returning variants (ForwardWithError) for better error handling. The artificial math (math.Sin in convolution, math.Sqrt in Index, runtime.GC calls) was clearly injected to make the "before" version slow; removing it is the entire point. The non-deterministic initialization (time.Now()) had to be replaced with a deterministic PRNG so tests can verify identical outputs.

## Phase 3: Success Criteria (Establish Measurable Goals)

Success meant passing 12 requirements mapped to tests: (1) preserve public API and output shapes, (2) reduce allocations to ≤4 per Forward call, (3) eliminate all goroutines and mutexes, (4) precompute strides and cache standardized weights, (5) use contiguous memory with explicit stride variables, (6) hoist loop invariants (kernelSize, kSquare), (7) deterministic results for repeated calls, (8) support batch sizes >1, (9) detect invalid shapes/stride/padding and return errors, (10) handle non-divisible group counts (e.g. 5 channels / 3 groups), (11) numerical stability for zero-variance inputs, (12) remove runtime.GC and artificial math. The "before" implementation passes only 3 tests (basic shape, batch size, zero-variance); the "after" must pass all 12.

## Phase 4: Map Requirements to Validation (Define Test Strategy)

Each requirement has a dedicated test in requirements_test.go. Tests run against both repository_before and repository_after by switching imports based on REPO_PATH environment variable. TestOptimizedForwardAllocationsWithinBudget uses testing.AllocsPerRun to measure allocations. TestOptimizedImplementationNoGoroutinesOrMutex scans the source for "sync.Mutex" and "go " keywords. TestPrecomputedStridesAndCachedWeightsPresent uses reflection to check for "strides" field in Tensor and "ws" field in WSConv2D. TestOptimizedUsesContiguousMemoryPatterns scans for "xStride" and "yStride" variables. TestHoistedInvariantsPresent scans for "kernelSize" and "kSquare". TestDeterministicResults runs Forward twice and compares outputs. TestInvalidShapeAndStrideHandling calls ForwardWithError with bad inputs. TestNonDivisibleGroupCountsHandled runs GroupNorm with 5 channels and 3 groups. TestNoForcedGCOrArtificialMath scans for "runtime.GC" and artificial math patterns. The evaluation driver runs tests for both before and after, and only passes if after succeeds.

## Phase 5: Scope the Solution

All changes live in repository_after/main.go. We keep the same package structure (one file, three types: Tensor, WSConv2D, GroupNorm) and the same public API (NewTensor, NewWSConv2D, NewGroupNorm, Forward). We add: (1) strides field to Tensor and ensureStrides() method, (2) ws (cached weights), wsValid flag, and kernelSize field to WSConv2D, (3) Prepare() and Invalidate() methods for explicit cache control, (4) ForwardWithError variants that return errors for invalid inputs, (5) deterministic LCG-based weight initialization, (6) non-divisible group handling in GroupNorm (base + remainder distribution). We remove: all goroutines, all mutexes, runtime.GC calls, artificial math in Index and Forward, time-based randomness. We don't touch repository_before except to ensure tests can import it. We don't change the test suite or evaluation logic.

## Phase 6: Trace Data Flow (Follow the Path)

Before: Forward() → standardizeWeights() (recompute every time, lock mutex, call GC) → spawn goroutine per output pixel → each goroutine locks global mutex → Index() locks mutex and runs 50 sqrt iterations → multiply by math.Sin(sum+1) → write output → wait for all goroutines. After: Forward() → standardizeWeights() checks wsValid flag, returns cached ws if valid, else recomputes once and sets wsValid → precompute all strides (xStrideN, xStrideC, xStrideH, xStrideW, yStrideN, yStrideC, yStrideH, yStrideW) → hoist invariants (k, kSquare, kernelSize) → nested loops (n, oc, oh, ow, ic, kh, kw) with manual index arithmetic (xBaseN + ic*xStrideC + ih*xStrideH + iw*xStrideW) → accumulate sum → write y.Data[yIdx] = sum + bias. No locks, no goroutines, no GC, no artificial math. GroupNorm: compute base = C / groups and rem = C % groups, distribute channels so first rem groups get base+1 channels and rest get base, compute mean and variance over each group's channels, normalize in-place.

## Phase 7: Anticipate Objections (Play Devil's Advocate)

Someone might say: "Removing goroutines loses parallelism." Counter: the global mutex serialized everything anyway, so we had zero parallelism and massive overhead. Sequential code is faster here. Another objection: "Caching standardized weights uses more memory." True, but it's a one-time allocation equal to the weight tensor size, and it eliminates recomputation on every forward pass—huge win for inference. "What if weights change?" We provide Invalidate() to clear the cache; in typical usage weights are frozen during inference. "Non-divisible groups are edge cases." They're explicitly tested (REQ-10) and common in practice (e.g. 5 channels / 3 groups in MobileNet variants). "Why add ForwardWithError when the original just panics?" Better error handling for production; we keep the original Forward() for API compatibility and add the error variant for callers who want it.

## Phase 8: Verify Invariants (Define Constraints)

We must preserve the public API: same function signatures for NewTensor, NewWSConv2D, NewGroupNorm, Forward. We must produce identical numerical outputs for all valid inputs (determinism requirement). We must handle all valid tensor shapes (4D NCHW) and detect invalid shapes, stride/padding mismatches, channel mismatches. We must not use goroutines, mutexes, or runtime.GC in the optimized version. We must allocate ≤4 times per Forward call (input tensor, output tensor, strides if not cached, standardized weights if not cached). We must support non-divisible group counts without dropping channels or producing NaN. We must use contiguous memory access (explicit stride arithmetic, not nested Index calls). We must hoist loop-invariant computations outside inner loops.

## Phase 9: Execute with Surgical Precision (Ordered Implementation)

First, fix Tensor: add strides []int field, compute strides in NewTensor and newTensor helper, add ensureStrides() to lazily compute if missing, rewrite Index() to use precomputed strides without locks or artificial math, add index4() helper for 4D access. Second, fix WSConv2D: replace time.Now() with deterministic LCG (seed=1, a=1664525, c=1013904223), add ws, wsValid, kernelSize fields, rewrite standardizeWeights() to check wsValid and return cached ws, add Prepare() and Invalidate() for cache control, rewrite Forward() to remove goroutines/mutex/GC/artificial math, precompute all strides and hoist invariants, use manual index arithmetic (xBaseN + ic*xStrideC + ...), add ForwardWithError() with shape/parameter validation. Third, fix GroupNorm: compute base and rem for non-divisible groups, distribute channels (first rem groups get base+1, rest get base), precompute strides, use manual index arithmetic, remove runtime.GC, add ForwardWithError() with validation. Fourth, update main() to call ForwardWithError and check errors.

## Phase 10: Measure Impact (Verify Completion)

Run tests against repository_before: 3 passed (TestPublicAPIForwardShapeMatches, TestBatchSizeSupport, TestZeroVarianceStability), 9 skipped (all optimization requirements). Run tests against repository_after: all 12 passed. Evaluation report shows before: success=false, exit_code=1, passed=3, failed=9; after: success=true, exit_code=0, passed=12, failed=0. Allocation test confirms ≤4 allocs per Forward. Source scans confirm no goroutines, no mutexes, no runtime.GC, presence of strides/ws fields, presence of xStride/yStride variables, presence of kernelSize/kSquare hoisting. Determinism test confirms identical outputs on repeated calls. Non-divisible group test confirms all channels are normalized. Invalid input tests confirm proper error returns.

## Phase 11: Document the Decision

Problem: repository_before was a neural network layer with correct math but catastrophic performance due to per-pixel goroutines with global mutex, forced GC, artificial computation, no caching, and non-deterministic initialization. Solution: eliminate concurrency overhead (sequential loops), cache standardized weights and tensor strides, use contiguous memory access with explicit stride arithmetic, hoist loop invariants, remove artificial math and GC calls, use deterministic PRNG, add error handling for invalid inputs, handle non-divisible group counts. Trade-off: slightly more memory for cached weights and strides, but massive speedup (orders of magnitude) and deterministic behavior. The optimized version is production-ready for inference workloads. Revisit if we need training (would need gradient computation and weight updates, which would invalidate the cache) or if we need actual parallelism (would need proper data parallelism across batch dimension, not per-pixel goroutines).

## Phase 12: Infrastructure and Tooling

- **go.work** at project root with repository_before, repository_after, tests, and evaluation modules so all imports resolve without manual GOPATH setup.
- **Docker** single app service with working_dir /app, REPO_PATH environment variable to switch test target, go1.21.13 runtime.
- **Tests** in tests/ with conditional imports: "repository_after" when REPO_PATH=/app/repository_after, "wsconv_gn" (repository_before) otherwise. Tests use usingAfter() helper to check REPO_PATH and skip optimization tests when running against before.
- **Evaluation** in evaluation/evaluation.go runs tests twice (REPO_PATH=before and after), captures stdout/stderr, parses test results, writes report.json with both runs, exits 0 only if after succeeds.
- **README** documents three commands: test before, test after, evaluate. No other supported workflows.
- **.gitignore** covers Go build artifacts, evaluation outputs, IDE files, OS cruft. go.work is committed for workspace setup.
- **Deterministic initialization** uses LCG with fixed seed so tests can verify identical outputs across runs. This is critical for REQ-07 (TestDeterministicResults).
- **Non-divisible groups** handled by computing base = C / groups and rem = C % groups, then distributing channels so first rem groups get base+1 channels and rest get base. This ensures all channels are covered and no group is empty. Critical for REQ-10 (TestNonDivisibleGroupCountsHandled).
