diff --git a/repository_after/.gitkeep b/repository_after/.gitkeep
new file mode 100644
index 0000000..e69de29
diff --git a/repository_after/ringbuf_test.go b/repository_after/ringbuf_test.go
new file mode 100644
index 0000000..fdcd57c
--- /dev/null
+++ b/repository_after/ringbuf_test.go
@@ -0,0 +1,195 @@
+package ringbuf_test
+
+import (
+	"context"
+	"fmt"
+	"runtime"
+	"sync"
+	"sync/atomic"
+	"testing"
+	"time"
+
+	ringbuf "kw5tnw-concurrent-safe-ring-buffer-test-suite/repository_before"
+)
+
+// Minimal interface so the integrity harness can be re-run against a buggy proxy.
+type pushPopper interface {
+	Push(int) bool
+	Pop() (int, bool)
+}
+
+func TestSequentialBasics(t *testing.T) {
+	rb := ringbuf.NewRingBuffer(4)
+
+	if v, ok := rb.Pop(); ok || v != 0 {
+		t.Fatalf("expected empty pop to return (0,false); got (%d,%v)", v, ok)
+	}
+
+	// Fill exactly to capacity.
+	for i := 1; i <= 4; i++ {
+		if ok := rb.Push(i); !ok {
+			t.Fatalf("expected Push(%d) to succeed", i)
+		}
+	}
+
+	// Now full.
+	if ok := rb.Push(999); ok {
+		t.Fatalf("expected Push to return false when full")
+	}
+
+	// Pop must be FIFO.
+	for i := 1; i <= 4; i++ {
+		v, ok := rb.Pop()
+		if !ok {
+			t.Fatalf("expected Pop to succeed for item %d", i)
+		}
+		if v != i {
+			t.Fatalf("FIFO violated: expected %d got %d", i, v)
+		}
+	}
+
+	// Now empty again.
+	if v, ok := rb.Pop(); ok || v != 0 {
+		t.Fatalf("expected empty pop to return (0,false); got (%d,%v)", v, ok)
+	}
+}
+
+func TestConcurrentIntegrity(t *testing.T) {
+	// N, M >= 10 and total operations >= 1,000,000.
+	const (
+		producers      = 10
+		consumers      = 10
+		perProducerOps = 100_000 // total pushes = 1,000,000
+		size           = 2048    // force saturation frequently
+	)
+	if producers < 10 || consumers < 10 {
+		t.Fatalf("test misconfigured: producers/consumers must be >= 10")
+	}
+
+	rb := ringbuf.NewRingBuffer(size)
+	res := runConcurrentIntegrity(t, rb, producers, consumers, perProducerOps)
+
+	if res.saturationCount == 0 {
+		t.Fatalf("expected saturationCount > 0 (Push(false) must happen under load); got %d", res.saturationCount)
+	}
+}
+
+type integrityResult struct {
+	saturationCount uint64
+}
+
+func runConcurrentIntegrity(t testing.TB, q pushPopper, producers, consumers, perProducerOps int) integrityResult {
+	t.Helper()
+
+	// No time.Sleep for sync; timeout is only hang detection.
+	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
+	defer cancel()
+
+	total := producers * perProducerOps
+
+	// Balance sheet: each value must be popped exactly once.
+	seen := make([]atomic.Uint32, total)
+
+	// Atomic counters keep the harness race-detector clean.
+	var pushedCount atomic.Uint64
+	var poppedCount atomic.Uint64
+	var saturationCount atomic.Uint64
+
+	var prodWG sync.WaitGroup
+	prodWG.Add(producers)
+	for p := 0; p < producers; p++ {
+		p := p
+		go func() {
+			defer prodWG.Done()
+			base := p * perProducerOps
+			for i := 0; i < perProducerOps; i++ {
+				val := base + i
+				for {
+					if ctx.Err() != nil {
+						return
+					}
+					if q.Push(val) {
+						pushedCount.Add(1)
+						break
+					}
+					// Backpressure: yield and retry until written.
+					saturationCount.Add(1)
+					runtime.Gosched()
+				}
+			}
+		}()
+	}
+
+	var consWG sync.WaitGroup
+	consWG.Add(consumers)
+	for c := 0; c < consumers; c++ {
+		go func() {
+			defer consWG.Done()
+			for {
+				if ctx.Err() != nil {
+					return
+				}
+				cur := poppedCount.Load()
+				if int(cur) >= total {
+					return
+				}
+				v, ok := q.Pop()
+				if !ok {
+					runtime.Gosched()
+					continue
+				}
+
+				// Defensive check: values must be within the pushed universe.
+				if v < 0 || v >= total {
+					failNow(t, fmt.Sprintf("popped out-of-range value %d (expected [0,%d))", v, total))
+					return
+				}
+
+				seen[v].Add(1)
+				poppedCount.Add(1)
+			}
+		}()
+	}
+
+	done := make(chan struct{})
+	go func() {
+		prodWG.Wait()
+		consWG.Wait()
+		close(done)
+	}()
+
+	select {
+	case <-done:
+		// proceed
+	case <-ctx.Done():
+		failNow(t, "concurrent integrity test timed out (possible deadlock/liveness failure)")
+	}
+
+	if got := int(pushedCount.Load()); got != total {
+		failNow(t, fmt.Sprintf("expected pushedCount=%d got %d", total, got))
+	}
+	if got := int(poppedCount.Load()); got != total {
+		failNow(t, fmt.Sprintf("expected poppedCount=%d got %d", total, got))
+	}
+
+	for i := 0; i < total; i++ {
+		cnt := seen[i].Load()
+		if cnt != 1 {
+			failNow(t, fmt.Sprintf("value %d seen %d times (expected exactly once)", i, cnt))
+		}
+	}
+
+	return integrityResult{saturationCount: saturationCount.Load()}
+}
+
+func failNow(t testing.TB, msg string) {
+	if tt, ok := t.(*testing.T); ok {
+		tt.Fatalf("%s", msg)
+		return
+	}
+	if tb, ok := t.(*testing.B); ok {
+		tb.Fatalf("%s", msg)
+		return
+	}
+	panic(msg)
+}
diff --git a/repository_before/ringbuffer.go b/repository_before/ringbuffer.go
deleted file mode 100644
index a16925b..0000000
--- a/repository_before/ringbuffer.go
+++ /dev/null
@@ -1,84 +0,0 @@
-// filename: ringbuffer.go
-package ringbuf
-
-import (
-	"runtime"
-	"sync/atomic"
-	"unsafe"
-)
-
-// RingBuffer is a fixed-size circular buffer using CAS for thread safety.
-type RingBuffer struct {
-	buffer []unsafe.Pointer
-	mask   uint64
-	head   uint64
-	tail   uint64
-	size   uint64
-}
-
-// NewRingBuffer creates a new buffer. Size must be a power of 2.
-func NewRingBuffer(size uint64) *RingBuffer {
-	if size&(size-1) != 0 {
-		panic("size must be a power of 2")
-	}
-	return &RingBuffer{
-		buffer: make([]unsafe.Pointer, size),
-		mask:   size - 1,
-		size:   size,
-	}
-}
-
-// Push adds an item to the buffer. Returns false if full.
-// Uses atomic CAS to reserve a slot and store data.
-func (r *RingBuffer) Push(val int) bool {
-	valPtr := unsafe.Pointer(uintptr(val))
-	for {
-		tail := atomic.LoadUint64(&r.tail)
-		head := atomic.LoadUint64(&r.head)
-
-		if tail-head >= r.size {
-			return false // Buffer is full
-		}
-
-		// Attempt to reserve the slot
-		if atomic.CompareAndSwapUint64(&r.tail, tail, tail+1) {
-			// Slot reserved. Write the data.
-			// specific slot index
-			idx := tail & r.mask
-			atomic.StorePointer(&r.buffer[idx], valPtr)
-			return true
-		}
-		// CAS failed, retry
-		runtime.Gosched()
-	}
-}
-
-// Pop removes an item. Returns value and true, or 0 and false if empty.
-func (r *RingBuffer) Pop() (int, bool) {
-	for {
-		head := atomic.LoadUint64(&r.head)
-		tail := atomic.LoadUint64(&r.tail)
-
-		if head >= tail {
-			return 0, false // Buffer is empty
-		}
-
-		// Attempt to claim the item
-		idx := head & r.mask
-		valPtr := atomic.LoadPointer(&r.buffer[idx])
-
-		if valPtr == nil {
-			// Writer reserved slot but hasn't written yet. Yield and retry.
-			runtime.Gosched()
-			continue
-		}
-
-		if atomic.CompareAndSwapUint64(&r.head, head, head+1) {
-			// Item claimed. Clear the slot for GC/safety (optional in pure int ring, but good practice)
-			atomic.StorePointer(&r.buffer[idx], nil)
-			return int(uintptr(valPtr)), true
-		}
-		// CAS failed, retry
-		runtime.Gosched()
-	}
-}
