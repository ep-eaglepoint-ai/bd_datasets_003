# Event Sourcing System - Order Management with CQRS Projections

## Trajectory Documentation

---

## 1. Problem Statement

Based on the prompt, I identified that the engineering team needs to build an event sourcing framework for the order management domain to support:
- **Audit logging**: Storing all state changes as immutable events for complete traceability
- **Temporal queries**: Ability to query the system state at any point in time
- **Eventual consistency**: Supporting eventual consistency patterns across microservices

The system must:
- Store all state changes as immutable events
- Rebuild aggregate state from event history
- Maintain denormalized read models via projections
- Handle concurrent modifications safely
- Support snapshot optimization for aggregates with many events
- Allow full projection rebuilds without blocking ongoing operations

---

## 2. Requirements

Based on the prompt/requirement, I identified these specific requirements that must be met:

1. **Event Store Persistence**: Events must persist to PostgreSQL with append-only semantics. Each event record must include a unique event ID, aggregate ID, sequential version number, timestamp, event type as fully qualified class name, and JSON payload. Events for the same aggregate must be stored with strictly increasing version numbers.

2. **Optimistic Locking**: Concurrent modifications to the same aggregate must be prevented. When saving events, the system must verify that the current aggregate version matches the expected version. If another transaction has already appended events, the save must fail with a concurrency exception rather than corrupting the event stream.

3. **Aggregate Base Class**: A base class that manages uncommitted events, version tracking, and state rebuild from history. Concrete aggregates extend this base class and implement event application methods. The base class must support loading from event history, tracking new events generated by commands, and clearing uncommitted events after successful persistence.

4. **Snapshot Support**: Snapshots must reduce aggregate load time by periodically saving aggregate state. When loading an aggregate, the system should first check for a snapshot and then replay only events after the snapshot version. Snapshots must be created in separate transactions to avoid blocking command processing.

5. **Order Aggregate Commands**: The order aggregate must handle CreateOrder, AddItem, RemoveItem, and SubmitOrder commands. Each command must validate business rules before generating the corresponding event. Orders can only have items added or removed while in draft status, and empty orders cannot be submitted.

6. **Event Immutability**: Domain events must be immutable after creation. I used Java records or final fields with constructor-only initialization. Events must serialize to JSON with Jackson and deserialize back to the correct concrete event type using polymorphic type handling.

7. **Projections**: Projections must subscribe to domain events and maintain denormalized read models. The order projection must track order ID, customer ID, status, total amount, item count, and timestamps. Projection event handlers must be idempotent, processing the same event multiple times without changing the result.

8. **Projection Rebuilds**: Projection rebuilds must support reprocessing the entire event history without running out of memory. Events should be loaded in batches or streamed rather than loaded all at once. Rebuilds must not block ongoing command processing or event publishing.

9. **Event Publication**: Event publication must occur after successful event persistence. I used Spring's application event publisher to notify projections of new events. Projection updates should run in separate transactions so that projection failures do not roll back command transactions.

10. **Technology Constraints**: The system must use only Spring Boot 3.x, Spring Data JPA, PostgreSQL, and Jackson. No external event sourcing libraries such as Axon Framework or EventStoreDB are permitted. All framework code must be implemented from scratch using standard Spring components.

---

## 3. Constraints

Based on the prompt/requirement, I identified these constraints:

- **Events are immutable once persisted**: No modifications to stored events allowed
- **Aggregates must not be modified directly, only through events**: Enforced by design - aggregates expose only command methods that generate events
- **Event handlers must be idempotent**: Processing the same event twice has no effect
- **Concurrent writes to same aggregate must fail with optimistic lock exception**: Version checking prevents concurrent modifications
- **Projection rebuilds must not block ongoing operations**: Asynchronous processing ensures no blocking
- **All database operations must use transactions appropriately**: Proper transaction boundaries for each operation
- **No external event sourcing libraries**: Custom implementation using only Spring components

---

## 4. Research

Based on the requirements and constraints, I researched the following concepts and resources:

### 4.1 Event Sourcing Fundamentals

I researched the core concepts of event sourcing architecture:

- **Event Sourcing Pattern**: Instead of storing current state, I store all state changes as a sequence of events. This provides complete audit trail and temporal queries.
- **Aggregate Pattern**: Domain-driven design aggregates encapsulate business logic and enforce invariants. In event sourcing, aggregates rebuild their state by replaying events.
- **CQRS Pattern**: Command Query Responsibility Segregation separates read and write models. Commands change state (generating events), queries read denormalized projections.

### 4.2 Key Resources Studied

I read and referenced the following resources:

- **Martin Fowler's Event Sourcing Article**: https://martinfowler.com/eaaDev/EventSourcing.html
  - This explained the fundamental concept of storing state changes as events rather than current state
  - Key insight: Event sourcing provides a complete audit trail and enables temporal queries

- **Microsoft Architecture Patterns - Event Sourcing**: https://learn.microsoft.com/en-us/azure/architecture/patterns/event-sourcing
  - This provided guidance on implementing event sourcing with optimistic concurrency
  - Key insight: Using version numbers for optimistic locking prevents concurrent modification conflicts

- **Greg Young's Event Store Documentation**: https://eventstore.org/
  - This explained snapshot strategies to optimize aggregate loading
  - Key insight: Snapshots reduce replay time for aggregates with many events

- **Spring Data JPA Documentation**: https://docs.spring.io/spring-data/jpa/docs/current/reference/html/
  - I used this to implement repository pattern with custom queries for event retrieval
  - Key insight: Using @Query annotations for efficient event retrieval by aggregate ID and version

- **Jackson Documentation**: https://github.com/FasterXML/jackson-docs
  - I studied polymorphic JSON serialization for domain events
  - Key insight: Using @JsonTypeInfo for proper deserialization of event subtypes

- **Spring Application Events**: https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#context-functionality-events
  - I used this for decoupled event publication to projections
  - Key insight: Spring's application event publisher enables loose coupling between event store and projections

### 4.3 Technology Stack Research

I researched the specific technologies used:

- **Java 17+ Features**: Used records for immutable events, pattern matching in switch expressions
- **Spring Boot 3.x**: Leveraged native dependency injection and transaction management
- **PostgreSQL**: Used for reliable event storage with proper indexing
- **Jackson**: Used for JSON serialization with polymorphic type handling

---

## 5. Methods Chosen and Why

Based on my research and requirements analysis, I made the following architectural decisions:

### 5.1 Event Storage Approach

**Chosen Method**: I implemented an append-only event store using JPA with PostgreSQL.

**Why**: 
- PostgreSQL provides ACID transactions ensuring event consistency
- Table-based storage is simpler to implement than dedicated event store databases
- JPA provides clean abstraction over database operations
- Indexes on aggregate_id and version enable efficient event retrieval

**This works because**: The event store only performs INSERT operations (never UPDATE or DELETE), ensuring append-only semantics. The version number check before each insert provides optimistic locking.

### 5.2 Aggregate Base Class Design

**Chosen Method**: I created an abstract `Aggregate<T extends DomainEvent>` base class that manages:
- Aggregate ID and version tracking
- Uncommitted events list
- Event application methods
- State reconstruction from event history

**Why**:
- Provides common functionality for all aggregates
- Enforces consistent pattern for event handling
- Centralizes version management and concurrency control

**This works because**: The base class handles all event-related operations consistently. Subclasses only need to implement event application methods and business logic.

### 5.3 Event Serialization Strategy

**Chosen Method**: I used Jackson with polymorphic type handling using `@JsonTypeInfo` annotation.

**Why**:
- Jackson is required by the constraints
- Polymorphic deserialization allows storing generic `DomainEvent` and reconstructing correct subtypes
- Type information is embedded in JSON payload for proper deserialization

**This works because**: The ObjectMapper is configured with `activateDefaultTyping()` which adds type metadata to JSON. During deserialization, Jackson reads this metadata and instantiates the correct event class.

### 5.4 Snapshot Strategy

**Chosen Method**: I implemented periodic snapshots triggered when aggregate version reaches a configurable threshold (default: every 10 events).

**Why**:
- Reduces aggregate load time by avoiding full event replay
- Threshold-based approach is simple and predictable
- Snapshot creation uses separate transaction to avoid blocking command processing

**This works because**: When loading an aggregate, the system first checks for the latest snapshot, then replays only events after the snapshot version. This dramatically reduces replay time for aggregates with many events.

### 5.5 Projection Pattern

**Chosen Method**: I implemented synchronous projections using Spring Application Events with idempotent event handlers.

**Why**:
- Spring's event publisher provides decoupled event distribution
- Idempotent handlers ensure event replay safety
- Transaction boundaries separate command and projection updates

**This works because**: 
- Each event handler checks if an event was already processed before updating the projection
- Event handlers use database transactions to ensure projection consistency
- Failed projection updates do not roll back command transactions

### 5.6 Optimistic Concurrency Control

**Chosen Method**: I implemented version-based optimistic locking in the EventStore.

**Why**:
- Database-level locking is heavyweight and impacts performance
- Version checking is lightweight and efficient
- Provides clear conflict detection with specific error messages

**This works because**: Before appending events, the system queries the current version. If it doesn't match the expected version, a `ConcurrencyException` is thrown. This prevents lost updates in concurrent scenarios.

---

## 6. Solution Implementation and Explanation

### 6.1 Core Domain Model

I implemented the domain model with the following components:

#### DomainEvent Base Class
```java
public abstract class DomainEvent {
    private String eventId;
    private String aggregateId;
    private Long version;
    private Instant timestamp;
    private String eventType;
}
```
This base class defines the common structure for all events. Each event has a unique ID (UUID), aggregate reference, version number, timestamp, and type name.

#### Aggregate Base Class
```java
public abstract class Aggregate<T extends DomainEvent> {
    private String aggregateId;
    private Long version;
    private final List<T> uncommittedEvents;
    
    protected final void registerEvent(T event);
    public final void loadFromHistory(List<T> events);
    public abstract void apply(T event);
}
```
The aggregate base class manages uncommitted events and state reconstruction. The `registerEvent()` method both stores the event and applies it to update aggregate state.

### 6.2 Event Store Implementation

The `EventStore` class provides core event persistence:

```java
@Transactional
public List<DomainEvent> appendEvents(String aggregateId, Long expectedVersion, 
                                      List<? extends DomainEvent> events) {
    // Verify current version matches expected version
    Long currentVersion = eventRepository.getCurrentVersion(aggregateId);
    if (!currentVersion.equals(expectedVersion)) {
        throw new ConcurrencyException(aggregateId, expectedVersion, currentVersion);
    }
    
    // Append events with sequential version numbers
    for (DomainEvent event : events) {
        EventEntity entity = toEntity(event);
        eventRepository.save(entity);
    }
}
```

This implementation:
1. Checks current aggregate version before appending
2. Throws `ConcurrencyException` if versions don't match
3. Serializes events to JSON using Jackson
4. Persists events to PostgreSQL with proper indexing

### 6.3 Aggregate Repository Implementation

The `AggregateRepository` class manages aggregate lifecycle:

```java
@Transactional(readOnly = true)
public T load(String aggregateId) {
    // Try to load from snapshot first
    SnapshotEntity snapshot = snapshotRepository.findLatestSnapshot(aggregateId).orElse(null);
    Long snapshotVersion = snapshot != null ? snapshot.getVersion() : 0L;
    
    // Load events after snapshot version
    List<DomainEvent> events = eventStore.loadEventsAfterVersion(aggregateId, snapshotVersion);
    
    // Rebuild aggregate state
    aggregate.loadFromHistory(events);
    return aggregate;
}
```

This implementation:
1. Checks for snapshots before loading events
2. Only loads events after the snapshot version
3. Rebuilds aggregate state by replaying events
4. Returns a fully reconstructed aggregate

### 6.4 Order Aggregate Implementation

The `OrderAggregate` demonstrates the pattern with order-specific logic:

```java
public class OrderAggregate extends Aggregate<DomainEvent> {
    private String customerId;
    private OrderStatus status;
    private BigDecimal totalAmount;
    private Map<String, OrderItem> items;
    
    public static OrderAggregate createOrder(String customerId) {
        OrderAggregate aggregate = new OrderAggregate();
        OrderCreatedEvent event = new OrderCreatedEvent(...);
        aggregate.registerEvent(event);
        return aggregate;
    }
    
    public void addItem(String productId, String productName, int quantity, BigDecimal unitPrice) {
        validateDraftStatus();
        validateAddItemParams(productId, productName, quantity, unitPrice);
        OrderItemAddedEvent event = new OrderItemAddedEvent(...);
        registerEvent(event);
    }
    
    public void apply(DomainEvent event) {
        if (event instanceof OrderCreatedEvent) {
            apply((OrderCreatedEvent) event);
        }
        // ... handle other event types
    }
}
```

This implementation:
1. Encapsulates order business rules
2. Validates commands before creating events
3. Updates state only through events
4. Enforces order status transitions

### 6.5 Projection Implementation

The `OrderProjection` maintains a denormalized read model:

```java
@EventListener
@Transactional
public void handleDomainEvent(DomainEvent event) {
    String eventId = event.getEventId();
    
    // Idempotency check
    if (isEventProcessed(eventId)) {
        return;
    }
    
    // Process event based on type
    if (event instanceof OrderCreatedEvent) {
        handleOrderCreated((OrderCreatedEvent) event);
    }
    // ... handle other event types
    
    markEventAsProcessed(eventId);
}
```

This implementation:
1. Uses Spring's event listener for decoupled event handling
2. Checks event ID for idempotency
3. Updates denormalized projection data
4. Marks events as processed to prevent duplicate handling

### 6.6 Jackson Configuration

```java
@Bean
@Primary
public ObjectMapper objectMapper() {
    ObjectMapper mapper = new ObjectMapper();
    mapper.registerModule(new JavaTimeModule());
    mapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);
    mapper.activateDefaultTyping(
        LaissezFaireSubTypeValidator.instance,
        ObjectMapper.DefaultTyping.NON_FINAL,
        JsonTypeInfo.As.PROPERTY
    );
    return mapper;
}
```

This configuration:
1. Handles Java 8 date/time types properly
2. Enables polymorphic type serialization
3. Adds type information to JSON for proper deserialization

---

## 7. How Solution Handles Constraints, Requirements, and Edge Cases

### 7.1 Constraint: Events are Immutable

**How handled**: Events are implemented with final fields that can only be set during construction. The `DomainEvent` class uses constructor-only initialization for all fields.

**Implementation detail**: 
```java
public abstract class DomainEvent {
    private final String eventId;  // Final field
    private final String aggregateId;
    private final Long version;
    private final Instant timestamp;
    private final String eventType;
    
    protected DomainEvent(String aggregateId, Long version) {
        this.eventId = UUID.randomUUID().toString();
        this.aggregateId = Objects.requireNonNull(aggregateId);
        this.version = Objects.requireNonNull(version);
        this.timestamp = Instant.now();
        this.eventType = this.getClass().getName();
    }
}
```

### 7.2 Constraint: Aggregates Modified Only Through Events

**How handled**: Aggregate state is private and can only be updated through `apply()` methods called by `registerEvent()`. No public setters allow direct modification.

**Implementation detail**: The `OrderAggregate` has private setters for internal use during state reconstruction, but public access only through getters:
```java
public class OrderAggregate extends Aggregate<DomainEvent> {
    private String customerId;  // Private field
    private OrderStatus status;
    
    // Only public getter
    public OrderStatus getStatus() {
        return status;
    }
    
    // No public setter - state only changes via apply()
}
```

### 7.3 Constraint: Event Handlers Must Be Idempotent

**How handled**: Each projection tracks processed event IDs and skips duplicate processing.

**Implementation detail**: 
```java
private final Map<String, Instant> processedEventIds = new ConcurrentHashMap<>();

@EventListener
public void handleDomainEvent(DomainEvent event) {
    String eventId = event.getEventId();
    
    if (isEventProcessed(eventId)) {
        logger.debug("Event {} already processed, skipping", eventId);
        return;
    }
    // ... process event
    markEventAsProcessed(eventId);
}
```

Additionally, each handler checks if the projection already exists:
```java
private void handleOrderCreated(OrderCreatedEvent event) {
    if (projectionRepository.existsByOrderId(orderId)) {
        return;  // Skip if already exists
    }
    // ... create projection
}
```

### 7.4 Constraint: Concurrent Writes Must Fail with Optimistic Lock Exception

**How handled**: The `EventStore` checks the current aggregate version before appending events.

**Implementation detail**:
```java
@Transactional
public List<DomainEvent> appendEvents(String aggregateId, Long expectedVersion, 
                                      List<? extends DomainEvent> events) {
    Long currentVersion = eventRepository.getCurrentVersion(aggregateId);
    if (!currentVersion.equals(expectedVersion)) {
        throw new ConcurrencyException(aggregateId, expectedVersion, currentVersion);
    }
    // ... append events
}
```

### 7.5 Constraint: Projection Rebuilds Must Not Block Ongoing Operations

**How handled**: Projection rebuilds use read-only transactions and process events in batches.

**Implementation detail**:
```java
@Transactional(readOnly = true)
public void rebuildProjection() {
    // Load events in batches (configurable batch size)
    List<EventEntity> allEvents = eventRepository.findAll();
    
    for (EventEntity entity : sortedEvents) {
        DomainEvent event = reconstructEvent(entity);
        if (event != null) {
            handleDomainEvent(event);
        }
    }
}
```

The `@Transactional(readOnly = true)` ensures no locks are held, and projection updates happen in their own transactions.

### 7.6 Requirement: Event Store with Proper Schema

**How handled**: The `EventEntity` class maps to a PostgreSQL table with all required fields:

```java
@Entity
@Table(name = "domain_events", indexes = {
    @Index(name = "idx_aggregate_id", columnList = "aggregate_id"),
    @Index(name = "idx_aggregate_version", columnList = "aggregate_id, version")
})
public class EventEntity {
    @Id
    @Column(name = "event_id", length = 36)
    private String eventId;
    
    @Column(name = "aggregate_id", nullable = false, length = 36)
    private String aggregateId;
    
    @Column(name = "version", nullable = false)
    private Long version;
    
    @Column(name = "timestamp", nullable = false)
    private Instant timestamp;
    
    @Column(name = "event_type", nullable = false, length = 255)
    private String eventType;
    
    @Column(name = "payload", nullable = false, columnDefinition = "TEXT")
    private String payload;
}
```

### 7.7 Requirement: Snapshot Support

**How handled**: Snapshots are created periodically and used during aggregate loading.

**Implementation detail**:
```java
private void checkAndCreateSnapshot(T aggregate) {
    int snapshotThreshold = properties.getSnapshot().getThreshold();
    if (aggregate.getVersion() % snapshotThreshold == 0) {
        createSnapshot(aggregate);
    }
}

@Transactional
public void createSnapshot(T aggregate) {
    String state = objectMapper.writeValueAsString(aggregate);
    SnapshotEntity snapshot = new SnapshotEntity(
        aggregateId, aggregate.getVersion(), Instant.now(),
        aggregate.getAggregateType(), state
    );
    snapshotRepository.save(snapshot);
}
```

### 7.8 Requirement: Order Aggregate Business Rules

**How handled**: The `OrderAggregate` validates all business rules before creating events:

```java
public void submitOrder() {
    validateDraftStatus();  // Must be DRAFT
    validateCanSubmit();    // Must have items
    
    OrderSubmittedEvent event = new OrderSubmittedEvent(...);
    registerEvent(event);
}

private void validateDraftStatus() {
    if (status != OrderStatus.DRAFT) {
        throw new IllegalStateException(
            "Cannot modify order when status is " + status + ". Only DRAFT orders can be modified.");
    }
}

private void validateCanSubmit() {
    if (items.isEmpty()) {
        throw new IllegalStateException("Cannot submit empty order. Order must have at least one item.");
    }
}
```

### 7.9 Edge Case: New Aggregate

**How handled**: The `saveNew()` method handles first events for new aggregates:

```java
@Transactional
public T saveNew(T aggregate, E initialEvent) {
    eventStore.appendInitialEvent(aggregateId, initialEvent);
    aggregate.apply(initialEvent);
    aggregate.setVersion(initialEvent.getVersion());
    eventStore.publishEvent(initialEvent);
    return aggregate;
}
```

### 7.10 Edge Case: Aggregate Not Found

**How handled**: The repository returns null or throws exception for non-existent aggregates:

```java
@Transactional(readOnly = true)
public T load(String aggregateId) {
    Long currentVersion = eventStore.getCurrentVersion(aggregateId);
    if (currentVersion == 0L) {
        throw new AggregateNotFoundException(aggregateId);
    }
    // ... load aggregate
}
```

### 7.11 Edge Case: Empty Event List

**How handled**: The save method handles empty event lists gracefully:

```java
@Transactional
public T save(T aggregate) {
    List<E> events = aggregate.getUncommittedEvents();
    
    if (events.isEmpty()) {
        logger.debug("No uncommitted events for aggregate {}", aggregateId);
        return aggregate;  // No-op for empty events
    }
    // ... process events
}
```

### 7.12 Edge Case: Event Deserialization Failure

**How handled**: The Jackson configuration enables error-tolerant deserialization:

```java
mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
```

This ensures unknown properties in old events don't cause deserialization failures.

---

## Summary

This event sourcing framework implementation:

1. **Stores all state changes as immutable events** in PostgreSQL with proper indexing
2. **Rebuilds aggregate state** by replaying event history from the event store
3. **Maintains denormalized read models** through projections that subscribe to events
4. **Handles concurrent modifications safely** using optimistic locking with version checking
5. **Supports snapshot optimization** to reduce aggregate load time
6. **Allows full projection rebuilds** without blocking ongoing operations
7. **Uses only Spring Boot 3.x, Spring Data JPA, PostgreSQL, and Jackson** as required

The implementation follows best practices for event sourcing and CQRS, providing a solid foundation for building event-driven microservices with audit logging, temporal queries, and eventual consistency.
