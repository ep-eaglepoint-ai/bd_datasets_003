{
            "instance_id": "UH668Z",
            "problem_statement": "The nightly aggregation pipeline loads entire CSV files into memory, causing performance and stability issues. The pipeline must efficiently process large datasets while maintaining output correctness.",
            "base_commit": "repository_before/",
            "test_patch": "tests/",
            "github_url": "https://github.com/ep-eaglepoint-ai/bd_datasets_003/tree/main/uh668z-optimize-large-csv-aggregation-pipeline-for-performance-and-memory-usage",
            "environment_setup": "Dockerfile",
            "FAIL_TO_PASS": [],
            "PASS_TO_PASS": []
        }
        