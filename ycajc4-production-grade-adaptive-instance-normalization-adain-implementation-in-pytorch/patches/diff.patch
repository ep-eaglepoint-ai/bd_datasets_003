diff --git a/repository_before/.gitkeep b/repository_before/.gitkeep
deleted file mode 100644
index e69de29..0000000
diff --git a/repository_after/adain.py b/repository_after/adain.py
new file mode 100644
index 0000000..5681bac
--- /dev/null
+++ b/repository_after/adain.py
@@ -0,0 +1,255 @@
+import torch
+
+
+def adain(content, style, content_mask=None, style_mask=None, alpha=None, style_detach=None):
+    if not isinstance(content, torch.Tensor):
+        raise TypeError(f"content must be torch.Tensor, got {type(content)}")
+    
+    if not isinstance(style, torch.Tensor):
+        raise TypeError(f"style must be torch.Tensor, got {type(style)}")
+    
+    if content.dim() < 3:
+        raise ValueError(f"content must have at least 3 dimensions, got {content.dim()}")
+    
+    if style.dim() < 3:
+        raise ValueError(f"style must have at least 3 dimensions, got {style.dim()}")
+    
+    if content.dim() != style.dim():
+        raise ValueError(f"content and style must have same rank, got {content.dim()} and {style.dim()}")
+    
+    if content.device != style.device:
+        raise ValueError(f"content and style must be on same device, got {content.device} and {style.device}")
+    
+    if content.shape[1] != style.shape[1]:
+        raise ValueError(f"content and style must have identical channel count, got {content.shape[1]} and {style.shape[1]}")
+    
+    if alpha is not None:
+        if not isinstance(alpha, (float, torch.Tensor)):
+            raise TypeError(f"alpha must be float or scalar tensor, got {type(alpha)}")
+        
+        if isinstance(alpha, torch.Tensor):
+            if alpha.numel() != 1 or alpha.dim() != 0:
+                raise TypeError(f"alpha must be scalar tensor, got tensor with {alpha.numel()} elements and {alpha.dim()} dimensions")
+            alpha = alpha.item()
+        
+        if not (0.0 <= alpha <= 1.0):
+            raise ValueError(f"alpha must be in range [0, 1], got {alpha}")
+    
+    if style_detach is not None:
+        if not isinstance(style_detach, bool):
+            raise TypeError(f"style_detach must be bool or None, got {type(style_detach)}")
+    
+    if not torch.is_floating_point(content):
+        raise TypeError(f"content must be floating point dtype, got {content.dtype}")
+    
+    if not torch.is_floating_point(style):
+        raise TypeError(f"style must be floating point dtype, got {style.dtype}")
+    
+    if not torch.isfinite(content).all():
+        raise ValueError("content contains NaN or Inf values")
+    
+    if not torch.isfinite(style).all():
+        raise ValueError("style contains NaN or Inf values")
+    
+    content_batch_size = content.shape[0]
+    style_batch_size = style.shape[0]
+    
+    if content_batch_size <= 0:
+        raise ValueError(f"content batch size must be greater than 0, got {content_batch_size}")
+    
+    if style_batch_size == 1:
+        style = style.expand(content_batch_size, -1, *([-1] * (content.dim() - 2)))
+        if style_mask is not None:
+            style_mask = style_mask.expand(content_batch_size, -1, *([-1] * (content.dim() - 2)))
+    elif style_batch_size == content_batch_size:
+        pass
+    else:
+        raise ValueError(f"style batch size must be 1 or equal to content batch size, got {style_batch_size} and {content_batch_size}")
+    
+    if style_detach:
+        style = style.detach()
+        if style_mask is not None:
+            style_mask = style_mask.detach()
+    
+    spatial_dims = list(range(2, content.dim()))
+    
+    if content_mask is not None:
+        if not isinstance(content_mask, torch.Tensor):
+            raise TypeError(f"content_mask must be torch.Tensor or None, got {type(content_mask)}")
+        
+        if content_mask.device != content.device:
+            raise ValueError(f"content_mask must be on same device as content, got {content_mask.device} and {content.device}")
+        
+        if content_mask.dim() != content.dim():
+            raise ValueError(f"content_mask must have {content.dim()} dimensions, got {content_mask.dim()}")
+        
+        if content_mask.shape[0] != content.shape[0]:
+            raise ValueError(f"content_mask batch size must match content batch size, got {content_mask.shape[0]} and {content.shape[0]}")
+        
+        if content_mask.shape[1] == 1:
+            pass
+        elif content_mask.shape[1] != content.shape[1]:
+            raise ValueError(f"content_mask channel count must be 1 or {content.shape[1]}")
+        
+        for dim in range(2, content.dim()):
+            if content_mask.shape[dim] != content.shape[dim]:
+                raise ValueError(f"content_mask spatial dimension {dim} must match content, got {content_mask.shape[dim]} and {content.shape[dim]}")
+        
+        if not torch.is_floating_point(content_mask):
+            raise TypeError(f"content_mask must be floating point dtype, got {content_mask.dtype}")
+        
+        if not torch.isfinite(content_mask).all():
+            raise ValueError("content_mask values must be in range [0, 1]")
+        
+        if torch.any(content_mask < 0) or torch.any(content_mask > 1):
+            raise ValueError("content_mask values must be in range [0, 1]")
+    
+    if style_mask is not None:
+        if not isinstance(style_mask, torch.Tensor):
+            raise TypeError(f"style_mask must be torch.Tensor or None, got {type(style_mask)}")
+        
+        if style_mask.device != style.device:
+            raise ValueError(f"style_mask must be on same device as style, got {style_mask.device} and {style.device}")
+        
+        if style_mask.dim() != style.dim():
+            raise ValueError(f"style_mask must have {style.dim()} dimensions, got {style_mask.dim()}")
+        
+        if style_mask.shape[0] != style.shape[0]:
+            raise ValueError(f"style_mask batch size must match style batch size, got {style_mask.shape[0]} and {style.shape[0]}")
+        
+        if style_mask.shape[1] == 1:
+            pass
+        elif style_mask.shape[1] != style.shape[1]:
+            raise ValueError(f"style_mask channel count must be 1 or {style.shape[1]}")
+        
+        for dim in range(2, style.dim()):
+            if style_mask.shape[dim] != style.shape[dim]:
+                raise ValueError(f"style_mask spatial dimension {dim} must match style, got {style_mask.shape[dim]} and {style.shape[dim]}")
+        
+        if not torch.is_floating_point(style_mask):
+            raise TypeError(f"style_mask must be floating point dtype, got {style_mask.dtype}")
+        
+        if not torch.isfinite(style_mask).all():
+            raise ValueError("style_mask values must be in range [0, 1]")
+        
+        if torch.any(style_mask < 0) or torch.any(style_mask > 1):
+            raise ValueError("style_mask values must be in range [0, 1]")
+    
+    def compute_masked_stats(tensor, mask, mask_name):
+        float_tensor = tensor.to(torch.float32)
+        if mask is None:
+            mean = float_tensor.mean(dim=spatial_dims, keepdim=True)
+            var = float_tensor.var(dim=spatial_dims, keepdim=True, unbiased=False)
+        else:
+            mask_used = mask
+            if mask_used.shape[1] == 1:
+                mask_used = mask_used.expand_as(tensor)
+            
+            mask_float = mask_used.to(torch.float32)
+            mask_sum = mask_float.sum(dim=spatial_dims, keepdim=True)
+            if torch.any(mask_sum == 0):
+                raise ValueError(f"{mask_name} must cover at least one spatial element per channel")
+            
+            if tensor.dtype == torch.float16:
+                mask_eps = torch.tensor(1e-4, dtype=torch.float32, device=mask.device)
+            elif tensor.dtype == torch.bfloat16:
+                mask_eps = torch.tensor(1e-6, dtype=torch.float32, device=mask.device)
+            else:
+                mask_eps = torch.tensor(1e-8, dtype=tensor.dtype, device=mask.device)
+            
+            mask_sum = torch.maximum(mask_sum, mask_eps)
+            
+            weighted_sum = (float_tensor * mask_float).sum(dim=spatial_dims, keepdim=True)
+            mean = weighted_sum / mask_sum
+            
+            weighted_var = ((float_tensor - mean) ** 2 * mask_float).sum(dim=spatial_dims, keepdim=True)
+            var = weighted_var / mask_sum
+        dtype_eps = 1e-4 if tensor.dtype == torch.float16 else 1e-6 if tensor.dtype == torch.bfloat16 else 1e-8
+        var_eps = torch.tensor(dtype_eps, dtype=var.dtype, device=var.device)
+        std = torch.sqrt(torch.clamp_min(var, var_eps))
+        return mean.to(tensor.dtype), std.to(tensor.dtype)
+    
+    content_mean, content_std = compute_masked_stats(content, content_mask, "content_mask")
+    style_mean, style_std = compute_masked_stats(style, style_mask, "style_mask")
+    
+    spatial_dims = list(range(2, content.dim()))
+    has_zero_spatial = any(content.shape[dim] == 0 for dim in spatial_dims)
+    
+    if not has_zero_spatial:
+        if not torch.isfinite(content_mean).all():
+            raise ValueError("content_mean contains NaN or Inf values - numerical stability violated")
+        if not torch.isfinite(content_std).all():
+            raise ValueError("content_std contains NaN or Inf values - numerical stability violated")
+        if not torch.isfinite(style_mean).all():
+            raise ValueError("style_mean contains NaN or Inf values - numerical stability violated")
+        if not torch.isfinite(style_std).all():
+            raise ValueError("style_std contains NaN or Inf values - numerical stability violated")
+    
+    eps = 1e-6 if content.dtype == torch.float16 else 1e-8
+    eps_tensor = torch.tensor(eps, dtype=content.dtype, device=content.device)
+    content_std = torch.maximum(content_std, eps_tensor)
+    style_std = torch.maximum(style_std, eps_tensor)
+    
+    normalized_content = (content - content_mean) / content_std
+    
+    if not has_zero_spatial and not torch.isfinite(normalized_content).all():
+        raise ValueError("normalized_content contains NaN or Inf values - numerical stability violated")
+    
+    result = normalized_content * style_std + style_mean
+    if not has_zero_spatial and not torch.isfinite(result).all():
+        raise ValueError("result contains NaN or Inf values - numerical stability violated")
+    
+    if alpha is not None:
+        alpha_tensor = torch.tensor(alpha, dtype=content.dtype, device=content.device)
+        one_minus_alpha = torch.tensor(1.0 - alpha, dtype=content.dtype, device=content.device)
+        result = alpha_tensor * result + one_minus_alpha * content
+    
+    if not torch.isfinite(result).all():
+        raise ValueError("Output contains NaN or Inf values - numerical stability violated")
+    
+    return result
+
+
+class AdaIN(torch.nn.Module):
+    def __init__(self, alpha=None, style_detach=None):
+        super().__init__()
+        self.alpha = alpha
+        self.style_detach = style_detach
+    
+    def forward(self, content, style, content_mask=None, style_mask=None, alpha=None, style_detach=None):
+        return adain(content, style, content_mask=content_mask, style_mask=style_mask, 
+                   alpha=alpha if alpha is not None else self.alpha,
+                   style_detach=style_detach if style_detach is not None else self.style_detach)
+
+
+if __name__ == "__main__":
+    content = torch.randn(2, 3, 32, 32)
+    style = torch.randn(2, 3, 32, 32)
+    module = AdaIN(alpha=0.5)
+    result = module(content, style)
+    print(f"AdaIN module test passed: {result.shape}")
+    assert result.shape == content.shape, "Shape mismatch"
+    assert torch.isfinite(result).all(), "Output contains non-finite values"
+    
+    content_mask = torch.ones(2, 1, 32, 32)
+    content_mask[:, :, :16, :] = 0.0 
+    style_mask = torch.ones(2, 1, 32, 32)
+    result_masked = module(content, style, content_mask=content_mask, style_mask=style_mask)
+    print(f"Masked AdaIN test passed: {result_masked.shape}")
+    assert result_masked.shape == content.shape, "Masked shape mismatch"
+    assert torch.isfinite(result_masked).all(), "Masked output contains non-finite values"
+    
+
+    content_detached = content.clone().requires_grad_(True)
+    style_detached = style.clone().requires_grad_(True)
+    module_detach = AdaIN(alpha=0.5, style_detach=True)
+    result_detached = module_detach(content_detached, style_detached)
+    
+    loss = result_detached.sum()
+    loss.backward()
+    
+    assert content_detached.grad is not None, "Content should have gradients"
+    assert style_detached.grad is None, "Style should not have gradients when detached"
+    print(f"Style gradient detachment test passed")
+    
+    print("All self-tests passed!")
