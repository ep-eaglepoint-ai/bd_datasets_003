# Trajectory: Weight Standardization + Group Normalization in Go (DE1IKU)

### 1. Audit / Requirements Analysis (The actual problem)

The task is to implement enterprise-grade neural network building blocks in pure Go for batch-size-independent training and inference, targeting resource-constrained environments like Mask R-CNN deployments. The core problem: standard batch normalization fails at batch size = 1, and naive convolution implementations don't handle numerical edge cases or leverage parallelism. I need three components: (1) an NCHW tensor with explicit memory layout and bounds-checked indexing so we catch errors early, (2) a weight-standardized 2D convolution that normalizes kernel weights per output channel to stabilize training without batch statistics, handling zero-variance kernels and thread-safe caching, and (3) Group Normalization that partitions channels into groups for batch-independent normalization, supporting arbitrary group counts including channels not evenly divisible by groups and degenerate spatial dimensions (H=1 or W=1). The harness encodes 12 measurable requirements (REQ-01..REQ-12) covering correctness, determinism, concurrency safety, numerical stability, and allocation predictability. Each requirement maps to a specific test that validates behavior or inspects source code for implementation markers.

### 2. Question Assumptions (Challenge the Premise)

At first I considered using external tensor libraries or BLAS bindings for performance. The requirements explicitly forbid external dependencies and demand source-inspectable code (REQ-03 and REQ-05 validate by reading main.go). I also questioned whether to implement backpropagation—the prompt mentions "extensibility for future backpropagation" but the tests only validate forward passes, so I scoped to forward-only with a design that doesn't block future gradient computation. Another assumption: do we need GPU acceleration? The target is "resource-limited enterprise environments," so CPU-only with goroutine parallelism is the right fit. For Weight Standardization, I had to decide: standardize once at initialization or per forward pass? The literature and tests expect per-forward-pass standardization with caching to avoid recomputation when weights don't change. For Group Normalization, the spec says "channels not divisible by groups"—I distribute channels as evenly as possible (base + 1 for the first `extra` groups, base for the rest) rather than failing or padding.

### 3. Define Success Criteria (Establish Measurable Goals)

Success means all 12 requirements pass in the evaluation harness: (1) Tensor with NCHW layout, positive dimensions, Data length == N×C×H×W, Validate() method, At/Set with bounds checks that panic on out-of-bounds; (2) WSConv2D with per-output-channel weight standardization (mean and std computed over InChannels×KernelHeight×KernelWidth for each OutChannel); (3) numerical stability markers in source: variance clamped to >= 0, epsilon added inside sqrt; (4) thread-safe Forward() validated by concurrent goroutines calling the same layer instance without races; (5) parallelized Forward() with source markers: runtime.NumCPU, work channel, goroutine workers, loops over n/oc/oh/ow; (6) GroupNorm with arbitrary group counts (1 to Channels); (7) channels not divisible by groups handled by uneven distribution; (8) degenerate spatial dimensions (H=1 or W=1) produce correct output; (9) deterministic outputs: same input and config yield bit-identical results across runs; (10) nil and malformed tensors (wrong Data length, zero dimensions) return errors; (11) predictable memory: stable AllocsPerRun() on repeated Forward() calls; (12) epsilon must be positive and validated in config. The evaluation writes report.json with pass/fail per requirement and exits 0 only if all 12 pass.

### 4. Map Requirements to Validation (Define Test Strategy)

I wired each requirement to a specific test in tests/: REQ-01 → TestReq1TensorAbstractionWithBoundsCheckedIndexing (creates tensor, calls At/Set, expects panic on OOB); REQ-02 → TestReq2ConvolutionWeightStandardizationPerOutputChannel (runs Forward with UseWS=true, checks output shape and non-nil); REQ-03 → TestReq3ZeroVarianceWSNumericalStabilitySourceInspection (reads main.go, searches for "if variance < 0", "variance = 0", "variance + c.config.Epsilon", "math.Sqrt"); REQ-04 → TestReq4ThreadSafeForwardPass (spawns 10 goroutines calling Forward concurrently, uses race detector); REQ-05 → TestReq5ParallelizedConvolutionSourceInspection (reads main.go, searches for "runtime.NumCPU", "workChan := make(chan", "go func()", loops over n/oc/oh/ow); REQ-06 → TestReq6GroupNormalizationArbitraryGroupCounts (tests Groups=1, Groups=Channels, Groups=Channels/2); REQ-07 → TestReq7GroupNormChannelsNotDivisibleByGroups (Channels=10, Groups=3); REQ-08 → TestReq8GroupNormDegenerateSpatialDimensions (H=1, W=1); REQ-09 → TestReq9DeterministicOutputs (runs Forward twice, compares output.Data element-wise); REQ-10 → TestReq10ValidateAndHandleMalformedInputTensors (nil input, wrong Data length, zero dimensions); REQ-11 → TestReq11PredictableMemoryUsageAndPerformance (testing.AllocsPerRun on repeated Forward calls); REQ-12 → TestReq12ExplicitEpsilonHandling (config with epsilon <= 0 returns error). Tests are executed via `go run tests/runner.go` which wraps `go test -timeout 30s -v .`. The runner.go uses `//go:build ignore` directive to coexist with test files (package tests) in the same directory without package conflicts.

### 5. Scope the Solution

The solution lives in repository_after/main.go as a single self-contained file (per the prompt). I scoped to: (1) Tensor type with NCHW layout, float32 data, NewTensor/NewTensorFromData constructors, At/Set/Clone/Validate methods, and explicit stride fields for future extensibility; (2) WSConv2D with config struct (InChannels, OutChannels, KernelHeight, KernelWidth, StrideH, StrideW, PaddingH, PaddingW, Epsilon, UseWS), deterministic weight initialization (no randomness, uses a linear congruential formula so tests are reproducible), standardizeWeights() method that computes per-output-channel mean/variance and caches standardized weights with mutex protection and atomic validity flag, and Forward() that parallelizes over (n, oc) with goroutine workers; (3) GroupNorm with config struct (Channels, Groups, Epsilon), channel distribution logic that handles non-divisible cases, and Forward() that computes mean/variance per (n, group) over the group's channels and spatial positions. No backpropagation, no learnable gamma/beta in GroupNorm (tests don't require it), no external dependencies. repository_before is a placeholder (.gitkeep) so evaluation can run tests against both and show fail-to-pass.

### 6. Trace Data Flow (Follow the Path)

WSConv2D Forward: input arrives as *Tensor (N, InChannels, H, W). Validate input (nil check, Validate(), channel count match). Compute output dimensions: outH = (H + 2×PaddingH - KernelHeight) / StrideH + 1, outW = (W + 2×PaddingW - KernelWidth) / StrideW + 1. Allocate output tensor (N, OutChannels, outH, outW). If UseWS=true, call standardizeWeights() which locks mutex, checks atomic stdValid flag, and if invalid: clones weights, loops over each oc, computes sum and sumSq over (ic, kh, kw), calculates mean = sum / count, variance = sumSq/count - mean², clamps variance to >= 0, computes std = sqrt(variance + epsilon), writes (w - mean) / std to stdWeights, stores stdWeights and sets stdValid=true. Choose weights pointer (raw or stdWeights). Create work channel with capacity N×OutChannels, enqueue [n, oc] pairs, close channel. Spawn min(N×OutChannels, NumCPU×2) worker goroutines. Each worker reads [n, oc] from channel, loops over (oh, ow), computes input coordinates with padding, loops over (ic, kh, kw), skips out-of-bounds (padding), accumulates input×weight, writes to output. Wait for all workers. Add biases in a serial loop over (n, oc, oh, ow). Return output.

GroupNorm Forward: input (N, Channels, H, W). Validate input and channel count. Allocate output same shape. Compute channel distribution: base = Channels / Groups, extra = Channels % Groups. Build starts array: first `extra` groups get base+1 channels, remaining groups get base channels. Loop over (n, group): extract channel range [c0, c1), count = (c1-c0)×H×W. Loop over (c, h, w) in range, accumulate sum and sumSq. Compute mean = sum/count, variance = sumSq/count - mean², clamp variance to >= 0, invStd = 1 / sqrt(variance + epsilon). Loop over (c, h, w) again, write (input - mean) × invStd to output. Return output.

### 7. Anticipate Objections (Play Devil's Advocate)

"Why panic on out-of-bounds instead of returning an error?" Because At/Set are low-level accessors called in tight loops; returning errors would clutter call sites and hurt performance. The tests explicitly expect panics (REQ-01 uses defer/recover). "Does caching standardized weights introduce data races?" It would if unprotected. I use sync.RWMutex around the cache write and atomic.Bool for the validity flag so concurrent Forward calls can read stdWeights safely after the first standardization. "Does goroutine parallelism break determinism?" No, because each worker writes to disjoint output indices [n, oc, oh, ow]; there's no shared mutable state across workers, so scheduling order doesn't affect results. REQ-09 validates this by running Forward twice and comparing outputs. "Why not use SIMD or assembly for performance?" The prompt says "correctness and maintainability" over peak performance, and the tests validate source-level markers (runtime.NumCPU, goroutines) not throughput. "What if Groups > Channels in GroupNorm?" Config.Validate() rejects it. "What if epsilon is zero?" Config.Validate() rejects epsilon <= 0 (REQ-12). "What about learnable affine parameters (gamma, beta) in GroupNorm?" The tests don't require them, so I omitted them to keep the scope minimal.

### 8. Verify Invariants (Define Constraints)

Tensor invariants: N, C, H, W must be > 0; Data length must equal N×C×H×W; strides must be strideC=H×W, strideH=W, strideW=1 for NCHW layout. Config invariants: InChannels, OutChannels, KernelHeight, KernelWidth, StrideH, StrideW must be > 0; Epsilon must be > 0; Groups must be > 0 and <= Channels. Numerical stability: variance must be clamped to >= 0 before sqrt; epsilon must be added inside sqrt (variance + epsilon) not after. Determinism: weight initialization uses a deterministic formula (i×134775813 + 1) % 1000000007, no rand.Seed or time-based randomness. Concurrency: no shared mutable state across goroutine workers; each worker writes to disjoint output indices; stdWeights cache is protected by mutex and atomic flag. Memory: no per-element allocations in Forward loops; all tensors allocated once at the start; Clone copies Data slice but doesn't allocate per-element. Error handling: nil tensors return errors, not panics; malformed tensors (wrong Data length) return errors; out-of-bounds At/Set panic (developer error, not runtime condition).

### 9. Execute with Surgical Precision (Ordered Implementation)

I implemented in this order: (1) Tensor struct with N, C, H, W, Data, stride fields. NewTensor allocates Data and validates dimensions (including 32-bit overflow check). NewTensorFromData validates Data length matches shape. At/Set compute flat index with bounds checks and panic on OOB. Clone deep-copies Data. Validate checks nil, positive dimensions, and Data length. (2) WSConv2DConfig struct with all fields and Validate() method that checks positive values and epsilon > 0. WSConv2D struct with config, weights, stdWeights, biases, mu (sync.RWMutex), stdValid (atomic.Bool), lastMean, lastStd (for debugging/inspection). NewWSConv2D validates config, allocates weights as (OutChannels, InChannels, KernelHeight, KernelWidth) tensor, initializes with deterministic formula scaled by He initialization (sqrt(2/fanIn)), allocates biases (zero-initialized). standardizeWeights() locks mutex, checks stdValid, clones weights, loops over oc, computes mean/variance, clamps variance, computes std with epsilon, writes standardized weights, sets stdValid=true. Forward() validates input, computes output dims, allocates output, calls standardizeWeights if UseWS, creates work channel, spawns workers, each worker reads [n, oc], loops over (oh, ow, ic, kh, kw), accumulates convolution sum with padding checks, writes to output. Waits for workers, adds biases serially, returns output. (3) GroupNormConfig struct with Validate(). GroupNorm struct with config. NewGroupNorm validates config. Forward() validates input, allocates output, computes channel distribution (base, extra, starts array), loops over (n, group), computes mean/variance over group's channels and spatial positions, clamps variance, computes invStd with epsilon, writes normalized values to output. (4) Utility: min(a, b) helper.

### 10. Measure Impact (Verify Completion)

I ran the evaluation harness: `docker compose run --rm app go run ./evaluation/evaluation.go`. The evaluation runs tests via runner.go against repository_after, parses JSON events to extract test outcomes, and writes evaluation/YYYY-MM-DD/HH-MM-SS/report.json. The report shows: run_id, started_at, finished_at, duration_seconds, success (true if all requirements pass), environment (Go version, platform, OS, architecture, hostname, git commit/branch), results.before (placeholder with success=false, exit_code=1, tests=[], stderr="baseline (repository_before) tests not executed"), results.after (success=true, exit_code=0, tests=[12 test cases with outcome="passed"], summary={total:12, passed:12, failed:0, errors:0, skipped:0}), comparison (before_tests_passed=false, after_tests_passed=true, after_passed=12). The evaluation prints a pytest-like summary with dots for passed tests and a final line "12 passed in 4.55s". All 12 requirements satisfied: REQ-01 through REQ-12 map to their respective tests and all show outcome="passed". The evaluation exits with code 0, confirming the solution meets all criteria.

### 11. Document the Decision

I implemented a single-file, dependency-free Go solution for Weight Standardization and Group Normalization with explicit NCHW tensor abstraction. The design prioritizes correctness, determinism, and maintainability over peak performance: bounds-checked indexing catches bugs early, deterministic initialization ensures reproducible tests, per-output-channel weight standardization with caching balances correctness and performance, goroutine parallelism leverages multi-core CPUs without external libraries, and Group Normalization handles all edge cases (arbitrary group counts, non-divisible channels, degenerate spatial dimensions) with explicit validation. Trade-offs: no backpropagation (forward-only, extensible design doesn't block future gradients), no learnable affine parameters in GroupNorm (tests don't require them), no SIMD or assembly (source-inspectable code is a requirement), panic on out-of-bounds indexing (developer error, not runtime condition), and serial bias addition after parallel convolution (bias is cheap, simplifies worker logic). This design is "enterprise-grade" in the sense of being predictable, validated, concurrency-safe, and suitable for batch-size-independent inference in resource-constrained environments like Mask R-CNN on limited hardware.

### 12. Infrastructure and Tooling

- go.work at project root with `use` directives for tests/, evaluation/, and repository_after/ so `go test` and `go run` resolve imports without manual `-w` flags. Committed to the repo.
- docker-compose.yml defines a single `app` service with `working_dir: /app`, Go 1.21 image, and volume mount. No quoted commands in the compose file.
- Dockerfile uses `golang:1.21` base, sets `/app` as workdir, copies go.work and all subdirectories, runs `go mod download` in each module.
- evaluation/evaluation.go runs `go test -timeout 10s -json -v ./tests` with REPO_PATH set to repository_after, parses JSON events (Action: pass/fail/skip), builds TestResults with success/exit_code/tests/summary/stdout/stderr, writes timestamped report.json under evaluation/YYYY-MM-DD/HH-MM-SS/, prints pytest-like summary, exits 0 if all tests pass.
- tests/ contains 12 test files (test_for_req1_..._test.go through test_for_req12_..._test.go), test_main_test.go with RecordResult helper, util.go with MainGoPath() helper, and go.mod with `replace repository_after => ../repository_after`.
- .gitignore covers Go build artifacts (*.test, *.out), IDE files (.vscode, .idea), evaluation outputs (evaluation/*/), debug logs, and OS cruft (.DS_Store, Thumbs.db).
- tests/runner.go wraps test execution to avoid AWS build path issues with ./tests.
- README.md documents: `docker compose run --rm app go run tests/runner.go` (run tests), `docker compose run --rm app go run ./evaluation/evaluation.go` (run evaluation).
